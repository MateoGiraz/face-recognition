{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "mtXtV4x5YdrF",
        "7gaAH9h8EKKj",
        "QzMbaS7UaJDo"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5ypQSL6XIWh"
      },
      "outputs": [],
      "source": [
        "# Encadenar iterables\n",
        "from itertools import chain\n",
        "\n",
        "# Proporciona una barra de progreso rápida\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Selección aleatoria de una lista sin repetición\n",
        "from random import sample\n",
        "\n",
        "# Interfaz para hacer gráficos y visualizaciones\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Computación científica\n",
        "import numpy as np\n",
        "\n",
        "# Manipulación de datos\n",
        "import pandas as pd\n",
        "\n",
        "# Para guardar y cargar modelos\n",
        "from joblib import dump, load\n",
        "\n",
        "# Extraer parches (pequeños subconjuntos de imágenes) de imágenes\n",
        "from sklearn.feature_extraction.image import PatchExtractor\n",
        "\n",
        "# data: conjunto de datos de muestra y funciones de carga\n",
        "# color: convertir imágenes entre espacios de color\n",
        "# feature: funciones para identificar y extraer características de imágenes\n",
        "from skimage import data, color, feature\n",
        "\n",
        "# Cambiar el tamaño de una imagen\n",
        "from skimage.transform import resize, rescale\n",
        "\n",
        "# Train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Descarga y carga en memoria un conjunto de datos de imágenes de caras de personas famosas\n",
        "from sklearn.datasets import fetch_lfw_people\n",
        "\n",
        "# Modelos\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "# Validación cruzada\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# Matriz de confusión\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# La curva ROC\n",
        "from sklearn.metrics import roc_curve , auc\n",
        "\n",
        "# Métricas\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Métricas custom\n",
        "from sklearn.metrics import make_scorer\n",
        "\n",
        "# Download csv\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Funciones auxiliares"
      ],
      "metadata": {
        "id": "GusJMQc6YIqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para extraer porciones de una imagen\n",
        "def extract_patches(img, N, scale=1.0, patch_size=(62,47), random_state=0):\n",
        "    # Calcula el tamaño del parche extraído basado en el factor de escala dado\n",
        "    H = img.shape[0]\n",
        "    W = img.shape[1]\n",
        "    H_patch = min(H , int(scale * patch_size[0]))\n",
        "    W_patch = min(W , int(scale * patch_size[1]))\n",
        "    extracted_patch_size = (H_patch, W_patch)\n",
        "\n",
        "    # Inicializa un objeto PatchExtractor con el tamaño de parche calculado,\n",
        "    # el número máximo de parches, y una semilla de estado aleatorio\n",
        "    extractor = PatchExtractor(patch_size=extracted_patch_size, max_patches=N, random_state=random_state)\n",
        "\n",
        "    # Extrae parches de la imagen dada\n",
        "    # img[np.newaxis] se utiliza la entrada de PatchExtractor es un conjunto de imágenes\n",
        "    patches = extractor.transform(img[np.newaxis])\n",
        "\n",
        "    # Si el factor de escala no es 1, redimensiona cada parche extraído\n",
        "    # al tamaño del parche original\n",
        "    if scale != 1:\n",
        "        patches = np.array([resize(patch, patch_size) for patch in patches])\n",
        "\n",
        "    # Devuelve la lista de parches extraídos (y posiblemente redimensionados)\n",
        "    return patches"
      ],
      "metadata": {
        "id": "3YGo99zVYKLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def non_max_suppression(indices, Ni, Nj, overlapThresh):\n",
        "    # Si no hay rectángulos, regresar una lista vacía\n",
        "    if len(indices) == 0:\n",
        "        return []\n",
        "\n",
        "    # Si las cajas son enteros, convertir a flotantes\n",
        "    if indices.dtype.kind == \"i\":\n",
        "        indices = indices.astype(\"float\")\n",
        "\n",
        "    # Inicializar la lista de índices seleccionados\n",
        "    pick = []\n",
        "\n",
        "    # Tomar las coordenadas de los cuadros\n",
        "    x1 = np.array([indices[i,0] for i in range(indices.shape[0])])\n",
        "    y1 = np.array([indices[i,1] for i in range(indices.shape[0])])\n",
        "    x2 = np.array([indices[i,0]+Ni for i in range(indices.shape[0])])\n",
        "    y2 = np.array([indices[i,1]+Nj for i in range(indices.shape[0])])\n",
        "\n",
        "    # Calcula el área de los cuadros y ordena los cuadros\n",
        "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
        "    idxs = np.argsort(y2)\n",
        "\n",
        "    # Mientras todavía hay índices en la lista de índices\n",
        "    while len(idxs) > 0:\n",
        "        # Toma el último índice de la lista y agrega el índice a la lista de seleccionados\n",
        "        last = len(idxs) - 1\n",
        "        i = idxs[last]\n",
        "        pick.append(i)\n",
        "\n",
        "        # Encontrar las coordenadas (x, y) más grandes para el inicio de la caja y las coordenadas (x, y) más pequeñas para el final de la caja\n",
        "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
        "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
        "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
        "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
        "\n",
        "        # Calcula el ancho y alto de la caja\n",
        "        w = np.maximum(0, xx2 - xx1 + 1)\n",
        "        h = np.maximum(0, yy2 - yy1 + 1)\n",
        "\n",
        "        # Calcula la proporción de superposición\n",
        "        overlap = (w * h) / area[idxs[:last]]\n",
        "\n",
        "        # Elimina todos los índices del índice de lista que tienen una proporción de superposición mayor que el umbral proporcionado\n",
        "        idxs = np.delete(idxs, np.concatenate(([last], np.where(overlap > overlapThresh)[0])))\n",
        "\n",
        "    # Devuelve solo las cajas seleccionadas\n",
        "    return indices[pick].astype(\"int\")"
      ],
      "metadata": {
        "id": "KxOHexo5YNC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# True Positive Rate\n",
        "def tpr_scorer(clf, X, y):\n",
        "  y_pred = clf.predict(X)\n",
        "  cm = confusion_matrix(y, y_pred)\n",
        "  tpr = cm[1,1]/(cm[1,1]+cm[1,0])\n",
        "  return tpr\n",
        "\n",
        "# False Positive Rate\n",
        "def fpr_scorer(clf, X, y):\n",
        "  y_pred = clf.predict(X)\n",
        "  cm = confusion_matrix(y, y_pred)\n",
        "  fpr = cm[0,1]/(cm[0,0]+cm[0,1])\n",
        "  return fpr\n",
        "\n",
        "# True Negative Rate\n",
        "def tnr_scorer(clf, X, y):\n",
        "  y_pred = clf.predict(X)\n",
        "  cm = confusion_matrix(y, y_pred)\n",
        "  tnr = cm[0,0]/(cm[0,0]+cm[0,1])\n",
        "  return tnr\n",
        "\n",
        "# True Negative Rate\n",
        "def fnr_scorer(clf, X, y):\n",
        "  y_pred = clf.predict(X)\n",
        "  cm = confusion_matrix(y, y_pred,)\n",
        "  fnr = cm[1,0]/(cm[1,0]+cm[1,1])\n",
        "  return fnr\n"
      ],
      "metadata": {
        "id": "uXMgTgUrYPOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define una función para realizar una ventana deslizante (sliding window) sobre una imagen.\n",
        "def sliding_window(img,\n",
        "                   patch_size=(62,47),  # Define el tamaño del parche (patch) basado en el primer parche positivo por defecto\n",
        "                   istep=2,  # Paso de desplazamiento en la dirección i (verticalmente)\n",
        "                   jstep=2,  # Paso de desplazamiento en la dirección j (horizontalmente)\n",
        "                   scale=1.0):  # Factor de escala para ajustar el tamaño del parche\n",
        "\n",
        "    # Calcula las dimensiones Ni y Nj del parche ajustadas por el factor de escala.\n",
        "    Ni, Nj = (int(scale * s) for s in patch_size)\n",
        "\n",
        "    # Itera a lo largo de la imagen en la dirección i\n",
        "    for i in range(0, img.shape[0] - Ni, istep):\n",
        "        # Itera a lo largo de la imagen en la dirección j\n",
        "        for j in range(0, img.shape[1] - Ni, jstep):\n",
        "\n",
        "            # Extrae el parche de la imagen usando las coordenadas actuales i, j.\n",
        "            patch = img[i:i + Ni, j:j + Nj]\n",
        "\n",
        "            # Si el factor de escala es diferente de 1, redimensiona el parche al tamaño original del parche.\n",
        "            if scale != 1:\n",
        "                patch = resize(patch, patch_size)\n",
        "\n",
        "            # Usa yield para devolver las coordenadas actuales y el parche.\n",
        "            # Esto convierte la función en un generador.\n",
        "            yield (i, j), patch"
      ],
      "metadata": {
        "id": "kMoAoSemYQXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset de rostros (LFW)"
      ],
      "metadata": {
        "id": "mtXtV4x5YdrF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos el dataset\n",
        "faces = fetch_lfw_people()\n",
        "positive_patches = faces.images\n",
        "positive_patches.shape"
      ],
      "metadata": {
        "id": "AX2XCqtKaGog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividimos en train y test\n",
        "positive_patches_train, positive_patches_test = train_test_split(\n",
        "    positive_patches,\n",
        "    test_size=0.1,\n",
        "    random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "YbqMjgo9o97O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Para subir las fotos de la siguiente celda"
      ],
      "metadata": {
        "id": "7gaAH9h8EKKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "id": "_7prYSmZEJgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset de fondos"
      ],
      "metadata": {
        "id": "QzMbaS7UaJDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tomamos algunas imágenes de sklearn\n",
        "imgs = ['camera',\n",
        "        'text',\n",
        "        'coins',\n",
        "        'moon',\n",
        "        'page',\n",
        "        'clock',\n",
        "        'immunohistochemistry',\n",
        "        'chelsea',\n",
        "        'coffee',\n",
        "        'hubble_deep_field'\n",
        "        ]\n",
        "\n",
        "backgrounds = []\n",
        "for name in imgs:\n",
        "    img = getattr(data, name)()\n",
        "    if len(img.shape) == 3 and img.shape[2] == 3:  # Chequeamos si la imagen es RGB\n",
        "        img = color.rgb2gray(img)\n",
        "    backgrounds.append(img)\n",
        "\n",
        "for i in range(31):\n",
        "    filename = str(i)+'.jpg'\n",
        "    img = plt.imread(filename)\n",
        "    img = color.rgb2gray(img)\n",
        "    backgrounds.append(img)\n",
        "\n",
        "print(len(backgrounds))"
      ],
      "metadata": {
        "id": "EVDC1ZK3aJ6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "5ihsofoC-9qU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definimos los datos y las HOG a usar en el experimento"
      ],
      "metadata": {
        "id": "gkDZwUiTbU5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resolution = 1\n",
        "scales = [0.5,1,2,4,8]\n",
        "proportion_train = 10\n",
        "proportion_test = 100\n",
        "num_patches_train = int((proportion_train * len(positive_patches_train))/(len(scales) * len(backgrounds)))\n",
        "num_patches_test = int((proportion_test * len(positive_patches_test))/(len(scales) * len(backgrounds)))\n",
        "\n",
        "orientations = 3\n",
        "pixels_per_cell = (8, 8)\n",
        "cells_per_block = (3, 3)\n",
        "\n",
        "experiment_name = '_R_' + str(resolution)\n",
        "experiment_name += '_S_' + str(scales)\n",
        "experiment_name += '_PTrain_' + str(proportion_train)\n",
        "experiment_name += '_PTest_' + str(proportion_test)\n",
        "experiment_name += '_O_' + str(orientations)\n",
        "experiment_name += '_C_' + str(pixels_per_cell)\n",
        "experiment_name += '_B_' + str(cells_per_block)\n",
        "\n",
        "print(experiment_name)"
      ],
      "metadata": {
        "id": "diT64a6tbWuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tamaño de las imágenes de rostros\n",
        "\n",
        "# Train\n",
        "positive_patches_train = np.array(\n",
        "    [rescale(positive_patches_train[i], resolution)\n",
        "    for i in tqdm(range(len(positive_patches_train)))]\n",
        "    )\n",
        "\n",
        "# Test\n",
        "positive_patches_test = np.array(\n",
        "    [rescale(positive_patches_test[i], resolution)\n",
        "    for i in tqdm(range(len(positive_patches_test)))]\n",
        "    )"
      ],
      "metadata": {
        "id": "B83uQqwHda28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "size = positive_patches[0].shape\n"
      ],
      "metadata": {
        "id": "COWYtV-yL8tN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraemos las imágenes de fondo\n",
        "\n",
        "# Train\n",
        "negative_patches_train = np.vstack(\n",
        "    [extract_patches(im, num_patches_train, scale, random_state=42)\n",
        "    for im in tqdm(backgrounds, desc='Procesando imágenes train')\n",
        "    for scale in scales]\n",
        "    )\n",
        "\n",
        "# Test\n",
        "negative_patches_test = np.vstack(\n",
        "    [extract_patches(im, num_patches_test, scale, random_state=0)\n",
        "    for im in tqdm(backgrounds, desc='Procesando imágenes test')\n",
        "    for scale in scales]\n",
        "    )"
      ],
      "metadata": {
        "id": "5BnKLz4Javbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Armamos la matriz de features y el vector de etiquetas\n",
        "\n",
        "# Train\n",
        "X_train = np.array(\n",
        "    [feature.hog(image=im,\n",
        "                 orientations=orientations,\n",
        "                 pixels_per_cell=pixels_per_cell,\n",
        "                 cells_per_block=cells_per_block)\n",
        "    for im in tqdm(chain(positive_patches_train, negative_patches_train))]\n",
        "    )\n",
        "y_train = np.zeros(X_train.shape[0])\n",
        "y_train[:positive_patches_train.shape[0]] = 1\n",
        "\n",
        "# Test\n",
        "X_test = np.array(\n",
        "    [feature.hog(image=im,\n",
        "                 orientations=orientations,\n",
        "                 pixels_per_cell=pixels_per_cell,\n",
        "                 cells_per_block=cells_per_block)\n",
        "    for im in tqdm(chain(positive_patches_test, negative_patches_test))]\n",
        "    )\n",
        "y_test = np.zeros(X_test.shape[0])\n",
        "y_test[:positive_patches_test.shape[0]] = 1"
      ],
      "metadata": {
        "id": "BcPrvRBkaxk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Shape X_train: ', X_train.shape)\n",
        "print('Shape y_train: ', y_train.shape)\n",
        "print('Shape X_test: ', X_test.shape)\n",
        "print('Shape y_test: ', y_test.shape)"
      ],
      "metadata": {
        "id": "dWJW_0ITyjwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Def to execute a model\n",
        "def executeModel(model, is_keras=False):\n",
        "  if is_keras:\n",
        "    # Para Keras, el fit ya no retorna el objeto model, por lo que se llama directamente\n",
        "    model.fit(X_train, y_train, epochs=10, batch_size=10, verbose=0)\n",
        "    # Keras utiliza el método `predict` para obtener las probabilidades directamente\n",
        "    y_pred_proba = model.predict(X_test).ravel()\n",
        "    # Para obtener las etiquetas predichas, se toma un umbral de decisión, comúnmente 0.5 para clasificación binaria\n",
        "    y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "  else:\n",
        "    # Para modelos de Scikit-learn\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_proba = model.predict_proba(X_test)[:,1]\n",
        "\n",
        "  # Métrcias\n",
        "  acc = accuracy_score(y_test, y_pred)\n",
        "  b_acc = balanced_accuracy_score(y_test, y_pred)\n",
        "  prec = precision_score(y_test,y_pred,average='macro')\n",
        "  rec = recall_score(y_test, y_pred, average='macro')\n",
        "  f1 = f1_score(y_test, y_pred)\n",
        "  auc = roc_auc_score(y_test, y_pred_proba)\n",
        "  tpr = tpr_scorer(model, X_test, y_test)\n",
        "  fpr = fpr_scorer(model, X_test, y_test)\n",
        "  tnr = tnr_scorer(model, X_test, y_test)\n",
        "  fnr = fnr_scorer(model, X_test, y_test)\n",
        "\n",
        "  # Guardamos en un dataframe\n",
        "\n",
        "  results = pd.DataFrame(\n",
        "      data={\n",
        "          'Métrica': ['Accuracy', 'Precision', 'Recall', 'F1', 'B_Accuracy', 'AUC', 'TPR', 'FPR', 'TNR', 'FNR'],\n",
        "          'Valor': [acc, prec, rec, f1, b_acc, auc,tpr,fpr,tnr,fnr]\n",
        "      }\n",
        "    )\n",
        "\n",
        "  display(results)\n",
        "\n",
        "  # build csv\n",
        "  model_name = str(model)\n",
        "\n",
        "  results.to_csv(experiment_name + '_' + model_name + '.csv', header=False)\n",
        "  files.download(experiment_name + '_' + model_name + '.csv')\n",
        "\n",
        "  # auc graphs\n",
        "  fig, ax = plt.subplots(1,2,figsize=(8, 8))\n",
        "\n",
        "  fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
        "  gmean = np.sqrt(tpr * (1 - fpr))\n",
        "  index = np.argmax(gmean)\n",
        "  thresholdOpt = round(thresholds[index], ndigits = 4)\n",
        "  fprOpt = round(fpr[index], ndigits = 4)\n",
        "  tprOpt = round(tpr[index], ndigits = 4)\n",
        "\n",
        "  ax[0].step(\n",
        "      fpr,\n",
        "      tpr,\n",
        "      lw=1,\n",
        "      alpha=1,\n",
        "  )\n",
        "\n",
        "  ax[0].plot(\n",
        "      fprOpt,\n",
        "      tprOpt,\n",
        "      marker = 'o'\n",
        "  )\n",
        "\n",
        "  ax[0].set(\n",
        "      xlim=[-0.05, 1.05],\n",
        "      ylim=[-0.05, 1.05],\n",
        "      xlabel=\"False Positive Rate\",\n",
        "      ylabel=\"True Positive Rate\",\n",
        "      title=f\"Curva ROC\",\n",
        "  )\n",
        "  ax[0].axis(\"square\")\n",
        "\n",
        "  ax[1].set_aspect('equal')\n",
        "  ax[1].set_xlim([-0.05, 0.1])\n",
        "  ax[1].set_xbound(lower=-0.05, upper=0.1)\n",
        "  ax[1].set_ylim([0.85,1])\n",
        "  ax[1].set_ybound(lower=0.85, upper=1.0)\n",
        "\n",
        "  ax[1].step(\n",
        "      fpr,\n",
        "      tpr,\n",
        "      lw=1,\n",
        "      alpha=1,\n",
        "  )\n",
        "\n",
        "  ax[1].plot(\n",
        "      fprOpt,\n",
        "      tprOpt,\n",
        "      marker = 'o'\n",
        "  )\n",
        "\n",
        "  ax[1].set(\n",
        "      xlabel=\"False Positive Rate\",\n",
        "      ylabel=\"True Positive Rate\",\n",
        "      title=f\"Zoom\",\n",
        "  )\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "  print(f'Umbral óptimo: {thresholdOpt}')\n",
        "  print(f'FPR: {fprOpt}, TPR: {tprOpt}')\n"
      ],
      "metadata": {
        "id": "BpMFY3LjGTke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "\n",
        "def executeKerasModel(model, X_train, y_train, X_test, y_test, epochs=10, batch_size=10):\n",
        "    # Entrenar el modelo\n",
        "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "\n",
        "    # Hacer predicciones y calcular probabilidades\n",
        "    y_pred_proba = model.predict(X_test).ravel()\n",
        "    y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "    # Calcular métricas\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    b_acc = balanced_accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred, average='macro')\n",
        "    rec = recall_score(y_test, y_pred, average='macro')\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    auc = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "    # Guardar resultados en un dataframe\n",
        "    results = pd.DataFrame(\n",
        "      data={\n",
        "          'Métrica': ['Accuracy', 'Precision', 'Recall', 'F1', 'B_Accuracy', 'AUC'],\n",
        "          'Valor': [acc, prec, rec, f1, b_acc, auc]\n",
        "      }\n",
        "    )\n",
        "\n",
        "    display(results)\n",
        "\n",
        "    # build csv\n",
        "    model_name = str(model)\n",
        "\n",
        "    results.to_csv(experiment_name + '_' + model_name + '.csv', header=False)\n",
        "    files.download(experiment_name + '_' + model_name + '.csv')\n",
        "\n",
        "    # Generar gráficos de la curva ROC\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
        "    gmean = np.sqrt(tpr * (1 - fpr))\n",
        "    index = np.argmax(gmean)\n",
        "    thresholdOpt = round(thresholds[index], ndigits = 4)\n",
        "    fprOpt = round(fpr[index], ndigits = 4)\n",
        "    tprOpt = round(tpr[index], ndigits = 4)\n",
        "\n",
        "    fig, ax = plt.subplots(1,2,figsize=(8, 8))\n",
        "    ax[0].step(fpr, tpr, lw=1, alpha=1)\n",
        "    ax[0].plot(fprOpt, tprOpt, marker='o')\n",
        "    ax[0].set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05], xlabel=\"False Positive Rate\", ylabel=\"True Positive Rate\", title=\"Curva ROC\")\n",
        "    ax[0].axis(\"square\")\n",
        "\n",
        "    ax[1].set_aspect('equal')\n",
        "    ax[1].set_xlim([-0.05, 0.1])\n",
        "    ax[1].set_xbound(lower=-0.05, upper=0.1)\n",
        "    ax[1].set_ylim([0.85,1])\n",
        "    ax[1].set_ybound(lower=0.85, upper=1.0)\n",
        "    ax[1].step(fpr, tpr, lw=1, alpha=1)\n",
        "    ax[1].plot(fprOpt, tprOpt, marker='o')\n",
        "    ax[1].set(xlabel=\"False Positive Rate\", ylabel=\"True Positive Rate\", title=\"Zoom\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(f'Umbral óptimo: {thresholdOpt}')\n",
        "    print(f'FPR: {fprOpt}, TPR: {tprOpt}')\n",
        "\n",
        "# Uso de la función\n",
        "# model = [tu modelo de Keras definido aquí]\n",
        "# executeKerasModel(model, X_train, y_train, X_test, y_test, 'experimento_1')\n"
      ],
      "metadata": {
        "id": "R0Ehhs9wxXY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Aca ejecutamos los modelos"
      ],
      "metadata": {
        "id": "J8xHngH92Sn6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# run logistic regression\n",
        "model = LogisticRegression(C=1, max_iter=1000)\n",
        "executeModel(model)"
      ],
      "metadata": {
        "id": "BWI4ewet2bKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run decision tree\n",
        "model = DecisionTreeClassifier(criterion = 'entropy', max_depth=11, random_state=42)\n",
        "executeModel(model)"
      ],
      "metadata": {
        "id": "ftdXeCcm3U5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run Adaptive Boosting\n",
        "model = AdaBoostClassifier(n_estimators=100, learning_rate=0.2)\n",
        "executeModel(model)"
      ],
      "metadata": {
        "id": "JdxQKl8W2gh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run Gradient Boosting\n",
        "model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.2, n_iter_no_change=5, tol=1e-4, validation_fraction=0.1)\n",
        "executeModel(model)"
      ],
      "metadata": {
        "id": "HHQPhWvJ3czn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run Bagging\n",
        "model = BaggingClassifier(n_estimators=10)\n",
        "executeModel(model)"
      ],
      "metadata": {
        "id": "s0V_PzSYnJWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run deep learning\n",
        "\n",
        "input_dimension = X_train.shape[1]\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(64, input_dim=input_dimension, activation='relu'),\n",
        "    Dense(16, input_dim=input_dimension, activation='relu'),\n",
        "    Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "executeKerasModel(model, X_train, y_train, X_test, y_test)\n"
      ],
      "metadata": {
        "id": "PVUkxVrxkhwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run random forest\n",
        "model = RandomForestClassifier(n_estimators=100, max_depth=5)\n",
        "executeModel(model)"
      ],
      "metadata": {
        "id": "l4Abj0mCNpnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test con varios rostros\n"
      ],
      "metadata": {
        "id": "mzn_X2DOHUJh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_image = plt.imread('Central.jpg')\n",
        "test_image = color.rgb2gray(test_image)\n",
        "test_image = rescale(test_image,0.5)\n",
        "test_image.shape"
      ],
      "metadata": {
        "id": "hZrOcpR7HWN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizamos la imagen\n",
        "# Buscamos la escala de los rostros\n",
        "fig, ax = plt.subplots()\n",
        "ax.imshow(test_image, cmap='gray')\n",
        "\n",
        "scale = 0.6\n",
        "Ni, Nj = (int(scale * s) for s in size)\n",
        "\n",
        "ax.add_patch(plt.Rectangle((0, 0), Nj, Ni, edgecolor='red', alpha=1, lw=1, facecolor='none'))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7-E_C-iUHYra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Utiliza la función de ventana deslizante en una imagen de prueba.\n",
        "# zip(*...) toma las tuplas generadas y las descompone en índices y parches.\n",
        "indices, patches = zip(*sliding_window(test_image, scale=scale))\n",
        "\n",
        "# Calcula las características HOG para cada parche y las almacena en un array.\n",
        "patches_hog = np.array([feature.hog(patch,\n",
        "                                    orientations=orientations,\n",
        "                                    pixels_per_cell=pixels_per_cell,\n",
        "                                    cells_per_block=cells_per_block) for patch in patches])\n",
        "\n",
        "# Muestra la forma del array de características HOG.\n",
        "patches_hog.shape"
      ],
      "metadata": {
        "id": "IfdOQGWdHZ7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicción\n",
        "labels = model.predict(patches_hog).astype(int)\n",
        "labels.sum()"
      ],
      "metadata": {
        "id": "Gra9M8RTHgdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Ni, Nj = (int(scale*s) for s in size)\n",
        "indices = np.array(indices)\n",
        "detecciones = indices[labels == 1]\n",
        "detecciones = non_max_suppression(np.array(detecciones),Ni,Nj, 0.3)\n",
        "\n",
        "# Visualizamos las detecciones\n",
        "fig, ax = plt.subplots()\n",
        "ax.imshow(test_image, cmap='gray')\n",
        "ax.axis('off')\n",
        "\n",
        "for i, j in detecciones:\n",
        "    ax.add_patch(plt.Rectangle((j, i), Nj, Ni, edgecolor='red',\n",
        "                               alpha=1, lw=1, facecolor='none'))\n",
        "\n",
        "plt.savefig('test_central.png')"
      ],
      "metadata": {
        "id": "zEcXDccNMZ1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Guardamos el modelo"
      ],
      "metadata": {
        "id": "mjo5CQHSg8lZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from joblib import dump, load\n",
        "\n",
        "dump(model, \"BestModel\" + '.joblib')"
      ],
      "metadata": {
        "id": "xERe2Bz8hADZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}